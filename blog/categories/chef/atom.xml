<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Chef | Toger Blog]]></title>
  <link href="http://www.toger.us/blog/categories/chef/atom.xml" rel="self"/>
  <link href="http://www.toger.us/"/>
  <updated>2018-09-18T07:09:38-07:00</updated>
  <id>http://www.toger.us/</id>
  <author>
    <name><![CDATA[Jason Martin jhmartin@toger.us]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Cloud-Init With CentOS7, Chef, and SELinux]]></title>
    <link href="http://www.toger.us/blog/2016/06/08/cloud-init-with-centos7-and-chef/"/>
    <updated>2016-06-08T20:57:00-07:00</updated>
    <id>http://www.toger.us/blog/2016/06/08/cloud-init-with-centos7-and-chef</id>
    <content type="html"><![CDATA[<p>The CentOS 7 AMI in Amazon comes with Cloud-Init (<code>cloud-init-0.7.5-10.el7.centos.1.x86_64</code>). This is quite handy as it assists in automating several bootup tasks. One of these tasks is to install and bootstrap Chef.  Unforunately, when SELinux is installed the Chef handler will fail.</p>

<p>Sample error:
```
[CLOUDINIT] util.py[DEBUG]: Restoring selinux mode for /var/lib (recursive=True)
[CLOUDINIT] util.py[DEBUG]: Running chef (<module 'cloudinit.config.cc_chef' from '/usr/lib/python2.7/site-packages/cloudinit/config/cc_chef.py'>) failed</p>

<pre><code>   Traceback (most recent call last):
     File "/usr/lib/python2.7/site-packages/cloudinit/stages.py", line 658, in _run_modules
       cc.run(run_name, mod.handle, func_args, freq=freq)
     File "/usr/lib/python2.7/site-packages/cloudinit/cloud.py", line 63, in run
       return self._runners.run(name, functor, args, freq, clear_on_fail)
     File "/usr/lib/python2.7/site-packages/cloudinit/helpers.py", line 197, in run
       results = functor(*args)
     File "/usr/lib/python2.7/site-packages/cloudinit/config/cc_chef.py", line 54, in handle
       util.ensure_dir(d)
     File "/usr/lib/python2.7/site-packages/cloudinit/util.py", line 1291, in ensure_dir
       os.makedirs(path)
     File "/usr/lib/python2.7/site-packages/cloudinit/util.py", line 167, in __exit__
       self.selinux.restorecon(path, recursive=self.recursive)
     File "/usr/lib64/python2.7/site-packages/selinux/__init__.py", line 95, in restorecon
       for fname in fnames]), None)
     File "/usr/lib64/python2.7/posixpath.py", line 246, in walk
       walk(name, func, arg)
     File "/usr/lib64/python2.7/posixpath.py", line 238, in walk
       func(arg, top, names)
     File "/usr/lib64/python2.7/site-packages/selinux/__init__.py", line 95, in &lt;lambda&gt;
       for fname in fnames]), None)
     File "/usr/lib64/python2.7/site-packages/selinux/__init__.py", line 85, in restorecon
       status, context = matchpathcon(path, mode)
   OSError: [Errno 2] No such file or directory
</code></pre>

<p>```</p>

<!-- more -->


<p>This proved to be most frustrating.  It was obviously failing while it was fixing the SELinux parameters under <code>/var/lib</code>, but it was not clear why.  There were no denied messages in the audit log. Of course <code>/var/lib</code> and <code>/var/lib/chef</code> existed. <code>/var/lib/chef</code> is a default directory listed in <code>/usr/lib/python2.7/site-packages/cloudinit/config/cc_chef.py</code>.</p>

<p>Adding in several debug statements led to determining that the issue was specific to <code>/var/lib/nfs/rpc_pipefs</code>. The file existed and had no special permissions, although it had a generic SELinux label as opposed to a nfs-specific value.  Further investigation showed that the root of the issue was in libselinux, which is looking up the intended label in <code>/etc/selinux/targeted/contexts/files/file_contents</code>:</p>

<p><code>
/usr/share/Modules/init(/.*)?   system_u:object_r:bin_t:s0
/var/lib/nfs/rpc_pipefs(/.*)?   &lt;&lt;none&gt;&gt;
</code></p>

<p>The selinux python library is expecting a label as above, and returns a Errno 2 &lsquo;No such file or directory&rsquo; if it hits the &lsquo;none&rsquo; value.  This error is returned to cloud-init and causes the chef handler to bomb out.
Adding a label to the file_contents file works around the issue but likely breaks NFS (if it were in use). The better approach would be for <code>util.py</code> to ignore the case where a new label cannot be found. If CentOS7 updated to the latest cloud-init there is a decent chance this is fixed.</p>

<p>Filed as <a href="https://bugs.centos.org/view.php?id=10990.">https://bugs.centos.org/view.php?id=10990.</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Chef Too Big for the Kitchen]]></title>
    <link href="http://www.toger.us/blog/2016/04/18/chef-too-big-for-the-kitchen/"/>
    <updated>2016-04-18T06:39:08-07:00</updated>
    <id>http://www.toger.us/blog/2016/04/18/chef-too-big-for-the-kitchen</id>
    <content type="html"><![CDATA[<p>While pondering running a full &lsquo;ride-the-wave&rsquo; auto-scaling solution in AWS, I looked closely at my Chef installation.  The environment is very Chef-heavy with fairly generic AMI that runs a slew of Chef recipes to bring it up to the needs of that particular role. The nodes are in Autoscale groups and get their role designation from the Launch Configuration.</p>

<p>On average a node invoked approximately 55 recipes (as recorded by seen_recipes in the audit cookbook).  Several of those recipes bring in resources from (authenticated) remote locations that have very good availability but are not in my direct control. Ignoring the remote-based recipes there is still a significant number of moving parts that can be disrupted unexpectedly, such as by other cookbook / role / KV store changes.  This is acceptable-if-not-ideal when nodes are generally brought into being under the supervision of an operator who can resolve any issues, or for when the odd 1-of-x00 pooled nodes dies and is automatically replaced. This risk is manageable when the environment is perpetually scaled for peak traffic.</p>

<p>However, when critical nodes are riding the wave of capacity then the chance that something will eventually break during scale-up and cause the &lsquo;wave&rsquo; to swamp the application becomes 100%. That requires an operator to adjust the problem under a significant time crunch as the application is overwhelmed by traffic &mdash; hardly a recipe for success.  The more likely scenario is breakage at some odd hour of the morning as users wake up, and the application fails before an operator can intervene to keep the application alive.</p>

<p>I looked at my Chef construction and realized it was less Infrastructure As Code (IaC) and more like Compile In Production (CIP).</p>

<!-- more -->


<p>IaC makes evokes the image that an application is manipulating infrastructure as though it were a reliable running probram, while CIP is more equivalent since it hits live repositories / pulls in dependencies that may need resolution at build time.  Running Chef based off of a generic AMI at machine provision time is akin to running maven build / maven install on each production machine as it is built. This is a slow and dangerous way to provision machines as any number of factors could prevent its success.  In development groups a build failure is significant but not a &lsquo;wake the VP&rsquo; level issue, unlike an application that cannot scale in time and fails.</p>

<p>With this in mind it is unfathomable to implement ride-the-wave on top of a lengthy Chef run.  It will eventually fail in a very messy and public manner.  Sound cookbook development and promotion practices can mitigate some of this, as can careful curation and mirroring of all external dependencies.  This impedes keeping up with security patches and diminishes the utility of community cookbooks that tend to fetch objects from canonical repositories.</p>

<p>Instead of Compile In Production, the standard development process of creating a build / deployable artifact should be followed, and in the same manner rely on minimal runtime configuration.  Tools like Packer and Docker (with a repo under my own control) go a long way towards this. In a Packer environment I have prebuilt AMIs. There is essentially nothing to fail at runtime. Similarly, in a Docker environment I need the full set of dependencies at build time and only a Docker repo at runtime.  A Docker repo is comparatively simple and much easier to monitor / control then of external dependencies.</p>

<p>With my provision-time dependencies narrowed done to essentially nothing or only a Docker repo, I can move forward with ride-the-wave capacity and still sleep at night not worrying about a random external failure causing my application to fail.</p>
]]></content>
  </entry>
  
</feed>
